{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgyiG9AJkAgY"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "conn = sqlite3.connect('main.db')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "iJeRIgTRkAgb",
        "outputId": "3f67aec9-7639-4441-9fc6-3deb486e3033"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       source_id first_name    last_name                     institution\n",
              "0             27       Alan       Murray                             NaN\n",
              "1             27    Anthony        Smith                             NaN\n",
              "2             27        Zoe       Butler                             NaN\n",
              "3             63      Yaser  Abu-Mostafa                             NaN\n",
              "4             60    Michael     Fleisher                             NaN\n",
              "...          ...        ...          ...                             ...\n",
              "30232       8693     Joshua         Wang                          Google\n",
              "30233       2302       Ruho        Kondo  Toyota Central R&D Labs., Inc.\n",
              "30234       2302    Keisuke       Kawano   Toyota Central R&D Labs., Inc\n",
              "30235       2302    Satoshi        Koide        Toyota Central R&D Labs.\n",
              "30236       2302     Takuro      Kutsuna   Toyota Central R&D Labs. Inc.\n",
              "\n",
              "[30237 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a353ebe3-3f27-45cf-8a5a-aa9f5528ed80\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>first_name</th>\n",
              "      <th>last_name</th>\n",
              "      <th>institution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan</td>\n",
              "      <td>Murray</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony</td>\n",
              "      <td>Smith</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe</td>\n",
              "      <td>Butler</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>Yaser</td>\n",
              "      <td>Abu-Mostafa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Michael</td>\n",
              "      <td>Fleisher</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30232</th>\n",
              "      <td>8693</td>\n",
              "      <td>Joshua</td>\n",
              "      <td>Wang</td>\n",
              "      <td>Google</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30233</th>\n",
              "      <td>2302</td>\n",
              "      <td>Ruho</td>\n",
              "      <td>Kondo</td>\n",
              "      <td>Toyota Central R&amp;D Labs., Inc.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30234</th>\n",
              "      <td>2302</td>\n",
              "      <td>Keisuke</td>\n",
              "      <td>Kawano</td>\n",
              "      <td>Toyota Central R&amp;D Labs., Inc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30235</th>\n",
              "      <td>2302</td>\n",
              "      <td>Satoshi</td>\n",
              "      <td>Koide</td>\n",
              "      <td>Toyota Central R&amp;D Labs.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30236</th>\n",
              "      <td>2302</td>\n",
              "      <td>Takuro</td>\n",
              "      <td>Kutsuna</td>\n",
              "      <td>Toyota Central R&amp;D Labs. Inc.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30237 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a353ebe3-3f27-45cf-8a5a-aa9f5528ed80')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a353ebe3-3f27-45cf-8a5a-aa9f5528ed80 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a353ebe3-3f27-45cf-8a5a-aa9f5528ed80');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-515d3c09-2048-4a41-8a2b-8e05e7d24596\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-515d3c09-2048-4a41-8a2b-8e05e7d24596')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-515d3c09-2048-4a41-8a2b-8e05e7d24596 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_189feea8-6b81-4c63-b14e-ca2233a92de1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('authors_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_189feea8-6b81-4c63-b14e-ca2233a92de1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('authors_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "authors_df",
              "summary": "{\n  \"name\": \"authors_df\",\n  \"rows\": 30237,\n  \"fields\": [\n    {\n      \"column\": \"source_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1952,\n        \"min\": 1,\n        \"max\": 9406,\n        \"num_unique_values\": 4522,\n        \"samples\": [\n          5676,\n          2528,\n          5716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6487,\n        \"samples\": [\n          \"Shameem\",\n          \"Tiejun\",\n          \"Sejun\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8713,\n        \"samples\": [\n          \"Ghassami\",\n          \"Grace\",\n          \"Heisele\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"institution\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2670,\n        \"samples\": [\n          \"Dalian University of Technology\",\n          \"Erasmus MC\",\n          \"Bosch Center for Artificial Intelligence (BCAI)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      source_id  year                                              title  \\\n",
              "0            27  1987                         Bit-Serial Neural Networks   \n",
              "1            63  1987                        Connectivity Versus Entropy   \n",
              "2            60  1987        The Hopfield Model with Multi-Level Neurons   \n",
              "3            59  1987                               How Neural Nets Work   \n",
              "4            69  1987  Spatial Organization of Neural Networks: A Pro...   \n",
              "...         ...   ...                                                ...   \n",
              "9675       5452  2019  Discrete Object Generation with Reversible Ind...   \n",
              "9676       4799  2019  Adaptively Aligned Image Captioning via Adapti...   \n",
              "9677       1827  2019         Fully Dynamic Consistent Facility Location   \n",
              "9678       8693  2019      Efficient Rematerialization for Deep Networks   \n",
              "9679       2302  2019  Flow-based Image-to-Image Translation with Fea...   \n",
              "\n",
              "                                               abstract  \\\n",
              "0                                                   NaN   \n",
              "1                                                   NaN   \n",
              "2                                                   NaN   \n",
              "3                                                   NaN   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "9675  The success of generative modeling in continuo...   \n",
              "9676  Recent neural models for image captioning usua...   \n",
              "9677  We consider classic clustering problems in ful...   \n",
              "9678  When training complex neural networks, memory ...   \n",
              "9679  Learning non-deterministic dynamics and intrin...   \n",
              "\n",
              "                                              full_text  \n",
              "0     573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...  \n",
              "1     1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...  \n",
              "2     278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...  \n",
              "3     442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...  \n",
              "4     740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...  \n",
              "...                                                 ...  \n",
              "9675  Discrete Object Generation\\n\\nwith Reversible ...  \n",
              "9676  Adaptively Aligned Image Captioning via\\n\\nAda...  \n",
              "9677  Fully Dynamic Consistent Facility Location\\n\\n...  \n",
              "9678  Efﬁcient Rematerialization for Deep Networks\\n...  \n",
              "9679  Flow-based Image-to-Image Translation\\n\\nwith ...  \n",
              "\n",
              "[9680 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50f68c99-f18c-492d-88fb-ced4b6338700\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>1987</td>\n",
              "      <td>Bit-Serial Neural Networks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>1987</td>\n",
              "      <td>Connectivity Versus Entropy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>1987</td>\n",
              "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59</td>\n",
              "      <td>1987</td>\n",
              "      <td>How Neural Nets Work</td>\n",
              "      <td>NaN</td>\n",
              "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>1987</td>\n",
              "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9675</th>\n",
              "      <td>5452</td>\n",
              "      <td>2019</td>\n",
              "      <td>Discrete Object Generation with Reversible Ind...</td>\n",
              "      <td>The success of generative modeling in continuo...</td>\n",
              "      <td>Discrete Object Generation\\n\\nwith Reversible ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9676</th>\n",
              "      <td>4799</td>\n",
              "      <td>2019</td>\n",
              "      <td>Adaptively Aligned Image Captioning via Adapti...</td>\n",
              "      <td>Recent neural models for image captioning usua...</td>\n",
              "      <td>Adaptively Aligned Image Captioning via\\n\\nAda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9677</th>\n",
              "      <td>1827</td>\n",
              "      <td>2019</td>\n",
              "      <td>Fully Dynamic Consistent Facility Location</td>\n",
              "      <td>We consider classic clustering problems in ful...</td>\n",
              "      <td>Fully Dynamic Consistent Facility Location\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9678</th>\n",
              "      <td>8693</td>\n",
              "      <td>2019</td>\n",
              "      <td>Efficient Rematerialization for Deep Networks</td>\n",
              "      <td>When training complex neural networks, memory ...</td>\n",
              "      <td>Efﬁcient Rematerialization for Deep Networks\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9679</th>\n",
              "      <td>2302</td>\n",
              "      <td>2019</td>\n",
              "      <td>Flow-based Image-to-Image Translation with Fea...</td>\n",
              "      <td>Learning non-deterministic dynamics and intrin...</td>\n",
              "      <td>Flow-based Image-to-Image Translation\\n\\nwith ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9680 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50f68c99-f18c-492d-88fb-ced4b6338700')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50f68c99-f18c-492d-88fb-ced4b6338700 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50f68c99-f18c-492d-88fb-ced4b6338700');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7246a4aa-7fc9-4876-a21e-d30985d40f1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7246a4aa-7fc9-4876-a21e-d30985d40f1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7246a4aa-7fc9-4876-a21e-d30985d40f1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3d330d5d-08f8-48d0-b291-f5584271778c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('papers_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3d330d5d-08f8-48d0-b291-f5584271778c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('papers_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "papers_df",
              "summary": "{\n  \"name\": \"papers_df\",\n  \"rows\": 9680,\n  \"fields\": [\n    {\n      \"column\": \"source_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1825,\n        \"min\": 1,\n        \"max\": 9406,\n        \"num_unique_values\": 4522,\n        \"samples\": [\n          5676,\n          2528,\n          5716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1987,\n        \"max\": 2019,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2018,\n          2002,\n          2013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9680,\n        \"samples\": [\n          \"Label Embedding Trees for Large Multi-Class Tasks\",\n          \"Catastrophic Interference in Human Motor Learning\",\n          \"Provably Correct Automatic Sub-Differentiation for Qualified Programs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6361,\n        \"samples\": [\n          \"We introduce algorithmic assurance, the problem of testing whether\\nmachine learning algorithms are conforming to their intended design\\ngoal. We address this problem by proposing an efficient framework\\nfor algorithmic testing. To provide assurance, we need to efficiently\\ndiscover scenarios where an algorithm decision deviates maximally\\nfrom its intended gold standard. We mathematically formulate this\\ntask as an optimisation problem of an expensive, black-box function.\\nWe use an active learning approach based on Bayesian optimisation\\nto solve this optimisation problem. We extend this framework to algorithms\\nwith vector-valued outputs by making appropriate modification in Bayesian\\noptimisation via the EXP3 algorithm. We theoretically analyse our\\nmethods for convergence. Using two real-world applications, we demonstrate\\nthe efficiency of our methods. The significance of our problem formulation\\nand initial solutions is that it will serve as the foundation in assuring\\nhumans about machines making complex decisions.\",\n          \"Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from high-dimensional  distributions in  Statistics and Machine learning. HMC is known to run very efficiently in practice and its popular second-order ``leapfrog\\\" implementation has long been conjectured to run in $d^{1/4}$ gradient evaluations. Here we show that this conjecture is true when sampling from strongly log-concave target distributions that satisfy a weak third-order regularity property associated with the input data.  Our regularity condition is weaker than the Lipschitz Hessian property and allows us to show faster convergence bounds for a much larger class of distributions than would be possible with the usual Lipschitz Hessian constant alone.  Important distributions that satisfy our regularity condition include posterior distributions used in Bayesian logistic regression for which the data satisfies an ``incoherence\\\" property. Our result compares favorably with the best available bounds for the class of strongly log-concave distributions, which grow like $d^{{1}/{2}}$ gradient evaluations with the dimension. Moreover, our simulations on synthetic data suggest that, when our regularity condition is satisfied, leapfrog HMC performs better than its competitors -- both in terms of accuracy and in terms of the number of gradient evaluations it requires.\",\n          \"Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efficient inference algorithms for a conditional random field using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences in the features used is small. This leads to efficient learning algorithms for these conditional random fields. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9673,\n        \"samples\": [\n          \"Nonparametric Multi-group Membership Model\\n\\nfor Dynamic Networks\\n\\nMyunghwan Kim\\nStanford University\\nStanford, CA 94305\\n\\nJure Leskovec\\n\\nStanford University\\nStanford, CA 94305\\n\\nmykim@stanford.edu\\n\\njure@cs.stanford.edu\\n\\nRelational data\\u2014like graphs, networks, and matrices\\u2014is often dynamic, where the relational struc-\\nture evolves over time. A fundamental problem in the analysis of time-varying network data is to\\nextract a summary of the common structure and the dynamics of the underlying relations between\\nthe entities. Here we build on the intuition that changes in the network structure are driven by dy-\\nnamics at the level of groups of nodes. We propose a nonparametric multi-group membership model\\nfor dynamic networks. Our model contains three main components: We model the birth and death of\\nindividual groups with respect to the dynamics of the network structure via a distance dependent In-\\ndian Buffet Process. We capture the evolution of individual node group memberships via a Factorial\\nHidden Markov model. And, we explain the dynamics of the network structure by explicitly mod-\\neling the connectivity structure of groups. We demonstrate our model\\u2019s capability of identifying the\\ndynamics of latent groups in a number of different types of network data. Experimental results show\\nthat our model provides improved predictive performance over existing dynamic network models on\\nfuture network forecasting and missing link prediction.\\n\\n1 Introduction\\n\\nStatistical analysis of social networks and other relational data is becoming an increasingly impor-\\ntant problem as the scope and availability of network data increases. Network data\\u2014such as the\\nfriendships in a social network\\u2014is often dynamic in a sense that relations between entities rise and\\ndecay over time. A fundamental problem in the analysis of such dynamic network data is to extract\\na summary of the common structure and the dynamics of the underlying relations between entities.\\n\\nAccurate models of structure and dynamics of network data have many applications. They allow us\\nto predict missing relationships [20, 21, 23], recommend potential new relations [2], identify clusters\\nand groups of nodes [1, 29], forecast future links [4, 9, 11, 24], and even predict group growth and\\nlongevity [15].\\n\\nHere we present a new approach to modeling network dynamics by considering time-evolving inter-\\nactions between groups of nodes as well as the arrival and departure dynamics of individual nodes\\nto these groups. We develop a dynamic network model, Dynamic Multi-group Membership Graph\\nModel, that identi\\ufb01es the birth and death of individual groups as well as the dynamics of node join-\\ning and leaving groups in order to explain changes in the underlying network linking structure. Our\\nnonparametric model considers an in\\ufb01nite number of latent groups, where each node can belong to\\nmultiple groups simultaneously. We capture the evolution of individual node group memberships\\nvia a Factorial Hidden Markov model. However, in contrast to recent works on dynamic network\\nmodeling [4, 5, 11, 12, 14], we explicitly model the birth and death dynamics of individual groups\\nby using a distance-dependent Indian Buffet Process [7]. Under our model only active/alive groups\\nin\\ufb02uence relationships in a network at a given time. Further innovation of our approach is that we\\nnot only model relations between the members of the same group but also account for links between\\nmembers and non-members. By explicitly modeling group lifespan and group connectivity structure\\nwe achieve greater modeling \\ufb02exibility, which leads to improved performance on link prediction and\\nnetwork forecasting tasks as well as to increased interpretability of obtained results.\\n\\n1\\n\\n\\fThe rest of the paper is organized as follows: Section 2 provides the background and Section 3\\npresents our generative model and motivates its parametrization. We discuss related work in Sec-\\ntion 4 and present model inference procedure in Section 5. Last, in Section 6 we provide experi-\\nmental results as well as analysis of the social network from the movie, The Lord of the Rings.\\n\\n2 Models of Dynamic Networks\\n\\nFirst, we describe general components of modern dynamic network models [4, 5, 11, 14]. In the\\nnext section we will then describe our own model and point out the differences to the previous work.\\n\\nDynamic networks are generally conceptualized as discrete time series of graphs on a \\ufb01xed set of\\nnodes N . Dynamic network Y is represented as a time series of adjacency matrices Y (t) for each\\ntime t = 1, 2, \\u00b7 \\u00b7 \\u00b7 , T . In this work, we limit our focus to unweighted directed as well as undirected\\nnetworks. So, each Y (t) is a N \\u00d7 N binary matrix where Y (t)\\nij = 1 if a link from node i to j exists\\nat time t and Y (t)\\n\\nij = 0 otherwise.\\n\\nEach node i of the network is associated with a number of latent binary features that govern the\\ninteraction dynamics with other nodes of the network. We denote the binary value of feature k of\\nnode i at time t by z(t)\\nik \\u2208 {0, 1}. Such latent features can be viewed as assigning nodes to multi-\\nple overlapping, latent clusters or groups [1, 21]. In our work, we interpret these latent features as\\nmemberships to latent groups such as social communities of people with the same interests or hob-\\nbies. We allow each node to belong to multiple groups simultaneously. We model each node-group\\nmembership using a separate Bernoulli random variable [17, 22, 29]. This is in contrast to mixed-\\nmembership models where the distribution over individual node\\u2019s group memberships is modeled\\nusing a multinomial distribution [1, 5, 12]. The advantage of our multiple-membership approach\\nis as follows. Mixed-membership models (i.e., multinomial distribution over group memberships)\\nessentially assume that by increasing the amount of node\\u2019s membership to some group k, the same\\nnode\\u2019s membership to some other group k\\u2032 has to decrease (due to the condition that the probabilities\\nnormalize to 1). On the other hand, multiple-membership models do not suffer from this assumption\\nand allow nodes to truely belong to multiple groups. Furthermore, we consider a nonparametric\\nmodel of groups which does not restrict the number of latent groups ahead of time. Hence, our\\nmodel adaptively learns the appropriate number of latent groups for a given network at a given time.\\n\\nIn dynamic network models, one also speci\\ufb01es a process by which nodes dynamically join and leave\\ngroups. We assume that each node i can join or leave a given group k according to a Markov model.\\nHowever, since each node can join multiple groups independently, we naturally consider factorial\\nhidden Markov models (FHMM) [8], where latent group membership of each node independently\\nevolves over time. To be concrete, each membership z(t)\\nik evolves through a 2-by-2 Markov transition\\nprobability matrix Q(t)\\n= r), where\\nr, s \\u2208 {0 = non-member, 1 = member}.\\n\\nk [r, s] corresponds to P (z(t)\\n\\nk where each entry Q(t)\\n\\nik = s|z(t\\u22121)\\n\\nik\\n\\nNow, given node group memberships z(t)\\nik at time t one also needs to specify the process of link\\ngeneration. Links of the network realize according to a link function f (\\u00b7). A link from node i to\\nnode j at time t occurs with probability determined by the link function f (z(t)\\nj\\u00b7 ). In our model,\\nwe develop a link function that not only accounts for links between group members but also models\\nlinks between the members and non-members of a given group.\\n\\ni\\u00b7 , z(t)\\n\\n3 Dynamic Multi-group Membership Graph Model\\n\\nNext we shall describe our Dynamic Multi-group Membership Graph Model (DMMG) and point out\\nthe differences with the previous work. In our model, we pay close attention to the three processes\\ngoverning network dynamics: (1) birth and death dynamics of individual groups, (2) evolution of\\nmemberships of nodes to groups, and (3) the structure of network interactions between group mem-\\nbers as well as non-members. We now proceed by describing each of them in turn.\\n\\nModel of active groups. Links of the network are in\\ufb02uenced not only by nodes changing member-\\nships to groups but also by the birth and death of groups themselves. New groups can be born and\\nold ones can die. However, without explicitly modeling group birth and death there exists ambiguity\\n\\n2\\n\\n\\fbetween group membership change and the birth/death of groups. For example, consider two dis-\\njoint groups k and l such that their lifetimes and members do not overlap. In other words, group l is\\nborn after group k dies out. However, if group birth and death dynamics is not explicitly modeled,\\nthen the model could interpret that the two groups correspond to a single latent group where all the\\nmembers of k leave the group before the members of l join the group. To resolve this ambiguity we\\ndevise an explicit model of birth/death dynamics of groups by introducing a notion of active groups.\\n\\nUnder our model, a group can be in one of two states: it can be either active (alive) or inactive (not\\nyet born or dead). However, once a group becomes inactive, it can never be active again. That is,\\nonce a group dies, it can never be alive again. To ensure coherence of group\\u2019s state over time, we\\nbuild on the idea of distance-dependent Indian Buffet Processes (dd-IBP) [7]. The IBP is named\\nafter a metaphorical process that gives rise to a probability distribution, where customers enter an\\nIndian Buffet restaurant and sample some subset of an in\\ufb01nitely long sequence of dishes. In the\\ncontext of networks, nodes usually correspond to \\u2018customers\\u2019 and latent features/groups correspond\\nto \\u2018dishes\\u2019. However, we apply dd-IBP in a different way. We regard each time step t as a \\u2018customer\\u2019\\nthat samples a set of active groups Kt. So, at the \\ufb01rst time step t = 1, we have P oisson(\\u03bb) number\\nof groups that are initially active, i.e., |K1| \\u223c P oisson(\\u03bb). To account for death of groups we\\nthen consider that each active group at time t \\u2212 1 can become inactive at the next time step t with\\nprobability \\u03b3. On the other hand, P oisson(\\u03b3\\u03bb) new groups are also born at time t. Thus, at each\\ntime currently active groups can die, while new ones can also be born. The hyperparameter \\u03b3\\ncontrols for how often new groups are born and how often old ones die. For instance, there will be\\nalmost no newborn or dead groups if \\u03b3 \\u2248 1, while there would be no temporal group coherence and\\npractically all the groups would die between consecutive time steps if \\u03b3 = 0.\\n\\nFigure 1(a) gives an example of the above process. Black circles indicate active groups and white\\ncircles denote inactive (not yet born or dead) groups. Groups 1 and 3 exist at t = 1 and Group 2\\nis born at t = 2. At t = 3, Group 3 dies but Group 4 is born. Without our group activity model,\\nGroup 3 could have been reused with a completely new set of members and Group 4 would have\\nnever been born. Our model can distinguish these two disjoint groups.\\n\\nFormally, we denote the number of active groups at time t by Kt = |Kt|. We also denote the state\\n(active/inactive) of group k at time t by W (t)\\nk = 1{k \\u2208 Kt}. For convenience, we also de\\ufb01ne a set\\nof newly active groups at time t be K+\\n\\nt = |K+\\nt |.\\nPutting it all together we can now fully describe the process of group birth/death as follows:\\n\\nk = 0 \\u2200t\\u2032 < t} and K +\\n\\nk = 1, W (t\\u2032)\\n\\nt = {k|W (t)\\n\\nfor t = 1\\nfor t > 1\\n\\nK +\\n\\nP oisson (\\u03b3\\u03bb) ,\\n\\nt \\u223c(cid:26)P oisson (\\u03bb) ,\\nk \\u223c\\uf8f1\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3\\n\\nBernoulli(1 \\u2212 \\u03b3)\\n1,\\n0,\\n\\nW (t)\\n\\nk\\n\\n= 1\\nt\\u2032=1 K +\\n\\nif W (t\\u22121)\\n\\nif Pt\\u22121\\n\\notherwise .\\n\\nt\\u2032 < k \\u2264Pt\\n\\nt\\u2032=1 K +\\n\\nt\\u2032\\n\\n(1)\\n\\nNote that under this model an in\\ufb01nite number of active groups can exist. This means our model au-\\ntomatically determines the right number of active groups and each node can belong to many groups\\nsimultaneously. We now proceed by describing the model of node group membership dynamics.\\n\\nDynamics of node group memberships. We capture the dynamics of nodes joining and leaving\\ngroups by assuming that latent node group memberships form a Markov chain. In this framework,\\nnode memberships to active groups evolve through time according to Markov dynamics:\\n\\nP (z(t)\\n\\nik |z(t\\u22121)\\n\\nik\\n\\n) = Qk =(cid:18) 1 \\u2212 ak\\n\\nbk\\n\\nak\\n\\n1 \\u2212 bk (cid:19) ,\\n\\nwhere matrix Qk[r, s] denotes a Markov transition from state r to state s, which can be a \\ufb01xed\\nparameter, group speci\\ufb01c, or otherwise domain dependent as long as it de\\ufb01nes a Markov transition\\nmatrix. Thus, the transition of node\\u2019s i membership to active group k can be de\\ufb01ned as follows:\\n\\nak, bk \\u223c Beta(\\u03b1, \\u03b2), z(t)\\n\\nik \\u223c W (t)\\n\\nk\\n\\n\\u00b7 Bernoulli(cid:18)a\\n\\n(t\\u22121)\\nik\\n\\n1\\u2212z\\nk\\n\\n(1 \\u2212 bk)z\\n\\n(t\\u22121)\\n\\nik (cid:19) .\\n\\n(2)\\n\\nTypically, \\u03b2 > \\u03b1, which ensures that group\\u2019s memberships are not too volatile over time.\\n\\n3\\n\\n\\f(a) Group activity model\\n\\n(b) Link function model\\n\\nFigure 1: (a) Birth and death of groups: Black circles represent active and white circles represent inactive\\n(unborn or dead) groups. A dead group can never become active again.\\ndenotes\\nbinary node group memberships. Entries of link af\\ufb01nity matrix \\u0398k denotes linking parameters between all 4\\ncombinations of members (z(t)\\nij , individual\\naf\\ufb01nities \\u0398k[z(t)\\n\\ni = 0). To obtain link probability p(t)\\n\\ni = 1) and non-members (z(t)\\n\\n] are combined using a logistic function g(\\u00b7)\\n\\n(b) Link function: z(t)\\n\\n, z(t)\\n\\ni\\n\\nj\\n\\nj\\n\\n.\\n\\nRelationship between node group memberships and links of the network. Last, we describe the\\npart of the model that establishes the connection between node\\u2019s memberships to groups and the\\nlinks of the network. We achieve this by de\\ufb01ning a link function f (i, j), which for given a pair of\\nnodes i, j determines their interaction probability p(t)\\n\\nij based on their group memberships.\\n\\nWe build on the Multiplicative Attribute Graph model [16, 18], where each group k is associated\\nwith a link af\\ufb01nity matrix \\u0398k \\u2208 R2\\u00d72. Each of the four entries of the link af\\ufb01nity matrix captures\\nthe tendency of linking between group\\u2019s members, members and non-members, as well as non-\\nmembers themselves. While traditionally link af\\ufb01nities were considered to be probabilities, we\\nrelax this assumption by allowing af\\ufb01nities to be arbitrary real numbers and then combine them\\nthrough a logistic function to obtain a \\ufb01nal link probability.\\n\\nThe model is illustrated in Figure 1(b). Given group memberships z(t)\\njk of nodes i and j at\\ntime t the binary indicators \\u201cselect\\u201d an entry \\u0398k[z(t)\\njk ] of matrix \\u0398k. This way linking tendency\\nfrom node i to node j is re\\ufb02ected based on their membership to group k. We then determine the\\noverall link probability p(t)\\n\\nij by combining the link af\\ufb01nities via a logistic function g(\\u00b7)1. Thus,\\n\\nik and z(t)\\n\\nik , z(t)\\n\\nij = f (z(t)\\np(t)\\n\\ni\\u00b7 , z(t)\\n\\nj\\u00b7 ) = g \\u01ebt +\\n\\n\\u0398k[z(t)\\n\\nik , z(t)\\n\\njk ]! , Yij \\u223c Bernoulli(p(t)\\n\\nij )\\n\\n(3)\\n\\n\\u221e\\n\\nXk=1\\n\\nwhere \\u01ebt is a density parameter that re\\ufb02ects the varying link density of network over time.\\n\\nNote that due to potentially in\\ufb01nite number of groups the sum of an in\\ufb01nite number of link af\\ufb01nities\\nmay not be tractable. To resolve this, we notice that for a given \\u0398k subtracting \\u0398k[0, 0] from all its\\nentries and then adding this value to \\u01ebt does not change the overall linking probability p(t)\\nij . Thus, we\\ncan set \\u0398k[0, 0] = 0 and then only a \\ufb01nite number of af\\ufb01nities selected by z(t)\\nik have to be considered.\\nFor all other entries of \\u0398k we use N (0, \\u03bd2) as a prior distribution.\\n\\nTo sum up, Figure 2 illustrates the three components of the DMMG in a plate notation. Group\\u2019s\\nstate W (t)\\nik is de\\ufb01ned as\\nthe FHMM over active groups. Then, the link between nodes i and j is determined based on the\\ngroups they belong to and the corresponding group link af\\ufb01nity matrices \\u0398.\\n\\nis determined by the dd-IBP process and each node-group membership z(t)\\n\\nk\\n\\n4 Related Work\\n\\nClassically, non-Bayesian approaches such as exponential random graph models [10, 27] have been\\nused to study dynamic networks. On the other hand, in the Bayesian approaches to dynamic network\\nanalysis latent variable models have been most widely used. These approaches differ by the struc-\\nture of the latent space that they assume. For example, euclidean space models [13, 24] place nodes\\n\\n1g(x) = exp(x)/(1 + exp(x))\\n\\n4\\n\\n\\fFigure 2: Dynamic Multi-group Membership Graph Model. Network Y depends on each node\\u2019s group mem-\\nberships Z and active groups W . Links of Y appear via link af\\ufb01nities \\u0398.\\n\\nin a low dimensional Euclidean space and the network evolution is then modeled as a regression\\nproblem of node\\u2019s future latent location. In contrast, our model uses HMMs, where latent vari-\\nables stochastically depend on the state at the previous time step. Related to our work are dynamic\\nmixed-membership models where a node is probabilistically allocated to a set of latent features. Ex-\\namples of this model include the dynamic mixed-membership block model [5, 12] and the dynamic\\nin\\ufb01nite relational model [14]. However, the critical difference here is that our model uses multi-\\nmemberships where node\\u2019s membership to one group does not limit its membership to other groups.\\nProbably most related to our work here are DRIFT [4] and LFP [11] models. Both of these models\\nconsider Markov switching of latent multi-group memberships over time. DRIFT uses the in\\ufb01nite\\nfactorial HMM [6], while LFP adds \\u201csocial propagation\\u201d to the Markov processes so that network\\nlinks of each node at a given time directly in\\ufb02uence group memberships of the corresponding node\\nat the next time. Compared to these models, we uniquely incorporate the model of group birth and\\ndeath and present a novel and powerful linking function.\\n\\n5 Model Inference via MCMC\\n\\nWe develop a Markov chain Monte Carlo (MCMC) procedure to approximate samples from the\\nposterior distribution of the latent variables in our model. More speci\\ufb01cally, there are \\ufb01ve types\\nof variables that we need to sample: node group memberships Z = {z(t)\\nik }, group states W =\\n{W (t)\\nk }, group membership transitions Q = {Qk}, link af\\ufb01nities \\u0398 = {\\u0398k}, and density parameters\\n\\u01eb = {\\u01ebt}. By sampling each type of variables while \\ufb01xing all the others, we end up with many\\nsamples representing the posterior distribution P (Z, W, Q, \\u0398, \\u01eb|Y, \\u03bb, \\u03b3, \\u03b1, \\u03b2). We shall now explain\\na sampling strategy for each varible type.\\n\\nSampling node group memberships Z. To sample node group membership z(t)\\nik , we use the\\nforward-backward recursion algorithm [26]. The algorithm \\ufb01rst de\\ufb01nes a deterministic forward\\npass which runs down the chain starting at time one, and at each time point t collects information\\nfrom the data and parameters up to time t in a dynamic programming cache. A stochastic backward\\npass starts at time T and samples each z(t)\\nik in backwards order using the information collected dur-\\ning the forward pass. In our case, we only need to sample z(T B\\nk indicate the\\nbirth time and the death time of group k. Due to space constraints, we discuss further details in the\\nextended version of the paper [19].\\n\\nk and T D\\n\\nwhere T B\\n\\nk :T D\\nk )\\n\\nik\\n\\nSampling group states W . To update active groups, we use the Metropolis-Hastings algorithm\\nwith the following proposal distribution P (W \\u2192 W \\u2032): We add a new group, remove an existing\\ngroup, or update the life time of an active group with the same probability 1/3. When adding a new\\ngroup k\\u2032 we select the birth and death time of the group at random such that 1 \\u2264 T B\\nk\\u2032 \\u2264 T D\\nk\\u2032 \\u2264 T .\\nFor removing groups we randomly pick one of existing groups k\\u2032\\u2032 and remove it by setting W (t)\\nk\\u2032\\u2032 = 0\\nfor all t. Finally, to update the birth and death time of an existing group, we select an existing group\\nand propose new birth and death time of the group at random. Once new state vector W \\u2032 is proposed\\nwe accept it with probability\\n\\nmin(cid:18)1,\\n\\nP (Y |W \\u2032)P (W \\u2032|\\u03bb, \\u03b3)P (W \\u2032 \\u2192 W )\\n\\nP (Y |W )P (W |\\u03bb, \\u03b3)P (W \\u2192 W \\u2032) (cid:19) .\\n\\n(4)\\n\\nWe compute P (W |\\u03bb, \\u03b3) and P (W \\u2032 \\u2192 W ) in a closed form, while we approximate the posterior\\nP (Y |W ) by sampling L Gibbs samples while keeping W \\ufb01xed.\\n\\n5\\n\\n\\fSampling group membership transition matrix Q. Beta distribution is a conjugate prior of\\nBernoulli distribution and thus we can sample each ak and bk in Qk directly from the posterior\\ndistribution: ak \\u223c Beta(\\u03b1 + N01,k, \\u03b2 + N00,k) and bk \\u223c Beta(\\u03b1 + N10,k, \\u03b2 + N11,k), where Nrs,k\\nis the number of nodes that transition from state r to s in group k (r, s \\u2208 {0 = non-member, 1 =\\nmember}).\\n\\nSampling link af\\ufb01nities \\u0398. Once node group memberships Z are determined, we update the entries\\nof link af\\ufb01nity matrices \\u0398k. Direct sampling of \\u0398 is intractable because of non-conjugacy of the\\nlogistic link function. An appropriate method in such case would be the Metropolis-Hastings that\\naccepts or rejects the proposal based on the likelihood ratio. However, to avoid low acceptance\\nrates and quickly move toward the mode of the posterior distribution, we develop a method based\\non Hybrid Monte Carlo (HMC) sampling [3]. We guide the sampling using the gradient of log-\\nlikelihood function with respect to each \\u0398k. Because links Y (t)\\nij are generated independently given\\ngroup memberships Z, the gradient with respect to \\u0398k[x, y] can be computed by\\n\\n\\u2212\\n\\n1\\n2\\u03c32 \\u03982\\n\\nk +Xi,j,t(cid:16)Y (t)\\n\\nij \\u2212 p(t)\\n\\nik = x, z(t)\\n\\njk = y} .\\n\\nij (cid:17) 1{z(t)\\n\\n(5)\\n\\nUpdating density parameter \\u01eb. Parameter vector \\u01eb is de\\ufb01ned over a \\ufb01nite dimension T . Therefore,\\nwe can update \\u01eb by maximizing the log-likelihood given all the other variables. We compute the\\ngradient update for each \\u01ebt and directly update \\u01ebt via a gradient step.\\n\\nUpdating hyperparameters. The number of groups over all time periods is given by a Poisson\\ndistribution with parameter \\u03bb (1 + \\u03b3 (T \\u2212 1)). Hence, given \\u03b3 we sample \\u03bb by using a Gamma\\nconjugate prior. Similarly, we can use the Beta conjugate prior for the group death process (i.e.,\\nBernoulli distribution) to sample \\u03b3. However, hyperparameters \\u03b1 and \\u03b2 do not have a conjugate\\nprior, so we update them by using a gradient method based on the sampled values of ak and bk.\\n\\nij\\n\\nTime complexity of model parameter estimation. Last, we brie\\ufb02y comment on the time com-\\nplexity of our model parameter estimation procedure. Each sample z(t)\\nik requires computation of\\nlink probability p(t)\\nfor all j 6= i. Since the expected number of active groups at each time is \\u03bb,\\nthis requires O(\\u03bbN 2T ) computations of p(t)\\nij . By caching the sum of link af\\ufb01nities between every\\npair of nodes sampling Z as well as W requires O(\\u03bbN 2T ) time. Sampling \\u0398 and \\u01eb also requires\\nO(\\u03bbN 2T ) because the gradient of each p(t)\\nij needs to be computed. Overall, our approach takes\\nO(\\u03bbN 2T ) to obtain a single sample, while models that are based on the interaction matrix between\\nall groups [4, 5, 11] require O(K 2N 2T ), where K is the expected number of groups. Furthermore,\\nit has been shown that O(log N ) groups are enough to represent networks [16, 18]. Thus, in practice\\nK (i.e., \\u03bb) is of order log N and the running time for each sample is O(N 2T log N ).\\n\\n6 Experiments\\n\\nWe evaluate our model on three different tasks. For quantitative evaluation, we perform missing link\\nprediction as well as future network forecasting and show our model gives favorable performance\\nwhen compared to current dynamic and static network models. We also analyze the dynamics of\\ngroups in a dynamic social network of characters in a movie \\u201cThe Lord of the Rings: The Two\\nTowers.\\u201d\\n\\nExperimental setup. For the two prediction experiments, we use the following three datasets. First,\\nthe NIPS co-authorships network connects two people if they appear on the same publication in\\nthe NIPS conference in a given year. Network spans T =17 years (1987 to 2003). Following [11]\\nwe focus on a subset of 110 most connected people over all time periods. Second, the DBLP co-\\nauthorship network is obtained from 21 Computer Science conferences from 2000 to 2009 (T =\\n10) [28]. We focus on 209 people by taking 7-core of the aggregated network for the entire time.\\nThird, the INFOCOM dataset represents the physical proximity interactions between 78 students at\\nthe 2006 INFOCOM conference, recorded by wireless detector remotes given to each attendee [25].\\nAs in [11] we use the processed data that removes inactive time slices to have T =50.\\n\\nTo evaluate the predictive performance of our model, we compare it to three baseline models. For\\na naive baseline model, we regard the relationship between each pair of nodes as the instance of\\n\\n6\\n\\n\\fModel\\n\\nNaive\\nLFRM\\nDRIFT\\n\\nDMMG\\n\\nTestLL\\n\\n-2030\\n-880\\n-758\\n\\n\\u2212624\\n\\nNIPS\\nAUC\\n\\n0.808\\n0.777\\n0.866\\n0.916\\n\\nF1\\n\\nTestLL\\n\\n-12051\\n0.177\\n-3783\\n0.195\\n-3108\\n0.296\\n0.434 \\u22122684\\n\\nDBLP\\nAUC\\n\\n0.814\\n0.784\\n0.916\\n0.939\\n\\nINFOCOM\\n\\nF1\\n\\nTestLL\\n\\nAUC\\n\\nF1\\n\\n-17821\\n0.300\\n-8689\\n0.146\\n-6654\\n0.421\\n0.492 \\u22126422\\n\\n0.677\\n0.946\\n0.973\\n0.976\\n\\n0.252\\n0.703\\n0.757\\n0.764\\n\\nTable 1: Missing link prediction. We bold the performance of the best scoring method. Our DMMG performs\\nthe best in all cases. All improvements are statistically signi\\ufb01cant at 0.01 signi\\ufb01cance level.\\n\\nindependent Bernoulli distribution with Beta(1, 1) prior. Thus, for a given pair of nodes, the link\\nprobability at each time equals to the expected probability from the posterior distribution given net-\\nwork data. Second baseline is LFRM [21], a model of static networks. For missing link prediction,\\nwe independently \\ufb01t LFRM to each snapshot of dynamic networks. For network forecasting task,\\nwe \\ufb01t LFRM to the most recent snapshot of a network. Even though LFRM does not capture time\\ndynamics, we consider this to be a strong baseline model. Finally, for the comparison with dynamic\\nnetwork models, we consider two recent state of the art models. The DRIFT model [4] is based\\non an in\\ufb01nite factorial HMM and authors kindly shared their implementation. We also consider the\\nLFP model [11] for which we were not able to obtain the implementation, but since we use the same\\ndatasets, we compare performance numbers directly with those reported in [11].\\n\\nTo evaluate predictive performance, we use various standard evaluation metrics. First, to assess\\ngoodness of inferred probability distributions, we report the log-likelihood of held-out edges. Sec-\\nond, to verify the predictive performance, we compute the area under the ROC curve (AUC). Last,\\nwe also report the maximum F1-score (F1) by scanning over all possible precision/recall thresholds.\\n\\nTask 1: Predicting missing links. To generate the datasets for the task of missing link prediction,\\nwe randomly hold out 20% of node pairs (i.e., either link or non-link) throughout the entire time\\nperiod. We then run each model to obtain 400 samples after 800 burn-in samples for each of 10\\nMCMC chains. Each sample gives a link probability for a given missing entry, so the \\ufb01nal link\\nprobability of a missing entry is computed by averaging the corresponding link probability over all\\nthe samples. This \\ufb01nal link probability provides the evaluation metric for a given missing data entry.\\n\\nTable 1 shows average evaluation metrics for each model and dataset over 10 runs. We also compute\\nthe p-value on the difference between two best results for each dataset and metric. Overall, our\\nDMMG model signi\\ufb01cantly outperforms the other models in every metric and dataset. Particularly\\nin terms of F1-score we gain up to 46.6% improvement over the other models.\\n\\nBy comparing the naive model and LFRM, we observe that LFRM performs especially poorly\\ncompared to the naive model in two networks with few edges (NIPS and DBLP). Intuitively this\\nmakes sense because due to the network sparsity we can obtain more information from the temporal\\ntrajectory of each link than from each snapshot of network. However, both DRIFT and DMMG\\nsuccessfully combine the temporal and the network information which results in better predictive\\nperformance. Furthermore, we note that DMMG outperforms the other models by a larger margin\\nas networks get sparser. DMMG makes better use of temporal information because it can explicitly\\nmodel temporally local links through active groups.\\n\\nLast, we also compare our model to the LFP model. The LFP paper reports AUC ROC score of\\n\\u223c0.85 for NIPS and \\u223c0.95 for INFOCOM on the same task of missing link prediction with 20%\\nheld-out missing data [11]. Performance of our DMMG on these same networks under the same\\nconditions is 0.916 for NIPS and 0.976 for INFOCOM, which is a strong improvement over LFP.\\n\\nTask 2: Future network forecasting. Here we are given a dynamic network up to time Tobs and\\nthe goal is to predict the network at the next time Tobs + 1. We follow the experimental protocol\\ndescribed in [4, 11]: We train the models on \\ufb01rst Tobs networks, \\ufb01x the parameters, and then for\\neach model we run MCMC sampling one time step into the future. For each model and network,\\nwe obtain 400 samples with 10 different MCMC chains, resulting in 400K network samples. These\\nnetwork samples provide a probability distribution over links at time Tobs + 1.\\n\\nTable 2 shows performance averaged over different Tobs values ranging from 3 to T -1. Overall,\\nDMMG generally exhibits the best performance, but performance results seem to depend on the\\ndataset. DMMG performs the best at 0.001 signi\\ufb01cance level in terms of AUC and F1 for the NIPS\\ndataset, and at 0.05 level for the INFOCOM dataset. While DMMG improves performance on AUC\\n\\n7\\n\\n\\fModel\\n\\nNaive\\nLFRM\\nDRIFT\\n\\nTestLL\\n\\n-547\\n-356\\n\\u2212148\\n\\nDMMG\\n\\n-170\\n\\nNIPS\\nAUC\\n\\n0.524\\n0.398\\n0.672\\n0.732\\n\\nF1\\n\\n0.130\\n0.011\\n0.084\\n0.196\\n\\nTestLL\\n\\n-3248\\n-1680\\n\\u22121324\\n\\nDBLP\\nAUC\\n0.668\\n0.492\\n0.650\\n\\n-1347\\n\\n0.652\\n\\nINFOCOM\\n\\nF1\\n\\nTestLL\\n\\nAUC\\n\\nF1\\n\\n0.243\\n0.024\\n0.122\\n0.245\\n\\n-774\\n-760\\n-661\\n\\n\\u2212625\\n\\n0.673\\n0.640\\n0.782\\n0.804\\n\\n0.270\\n0.248\\n0.381\\n0.392\\n\\nTable 2: Future network forecasting. DMMG performs best on NIPS and INFOCOM while results on DBLP\\nare mixed.\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n(a) Group 1\\n\\n(b) Group 2\\n\\n(c) Group 3\\n\\nFigure 3: Group arrival and departure dynamics of different characters in the Lord of the Rings. Dark areas in\\nthe plots correspond to a give node\\u2019s (y-axis) membership to each group over time (x-axis)\\n\\n.\\n\\n(9%) and F1 (133%), DRIFT achieves the best log-likelihood on the NIPS dataset. In light of our\\nprevious observations, we conjecture that this is due to change in network edge density between\\ndifferent snapshots. On the DBLP dataset, DRIFT gives the best log-likelihood, the naive model\\nperforms best in terms of AUC, and DMMG is the best on F1 score. However, in all cases of DBLP\\ndataset, the differences are not statistically signi\\ufb01cant. Overall, DMMG performs the best on NIPS\\nand INFOCOM and provides comparable performance on DBLP.\\n\\nTask 3: Case study of \\u201cThe Lord of the Rings: The Two Towers\\u201d social network. Last, we also\\ninvestigate groups identi\\ufb01ed by our model on a dynamic social network of characters in a movie,\\nThe Lord of the Rings: The Two Towers. Based on the transcript of the movie we created a dynamic\\nsocial network on 21 characters and T =5 time epochs, where we connect a pair of characters if they\\nco-appear inside some time window.\\n\\nWe \\ufb01t our model to this network and examine the results in Figure 3. Our model identi\\ufb01ed three\\ndynamic groups, which all nicely correspond to the Lord of the Rings storyline. For example,\\nthe core of Group 1 corresponds to Aragorn, elf Legolas, dwarf Gimli, and people in Rohan who\\nin the end all \\ufb01ght against the Orcs. Similarly, Group 2 corresponds to hobbits Sam, Frodo and\\nGollum on their mission to destroy the ring in Mordor, and are later joined by Faramir and ranger\\nMadril. Interestingly, Group 3 evolving around Merry and Pippin only forms at t=2 when they start\\ntheir journey with Treebeard and later \\ufb01ght against wizard Saruman. While the \\ufb01ght occurs in two\\nseparate places we \\ufb01nd that some scenes are not distinguishable, so it looks as if Merry and Pippin\\nfought together with Rohan\\u2019s army against Saruman\\u2019s army.\\n\\nAcknowledgments\\n\\nWe thank Creighton Heaukulani and Zoubin Ghahramani for sharing data and code. This research\\nhas been supported in part by NSF IIS-1016909, CNS-1010921, IIS-1149837, IIS-1159679, IARPA\\nAFRL FA8650-10-C-7058, Okawa Foundation, Docomo, Boeing, Allyes, Volkswagen, Intel, Alfred\\nP. Sloan Fellowship and the Microsoft Faculty Fellowship.\\n\\nReferences\\n\\n[1] E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed membership stochastic blockmodels.\\n\\nJMLR, 9, 2008.\\n\\n[2] L. Backstrom and J. Leskovec. Supervised random walks: Predicting and recommending links in social\\n\\nnetworks. In WSDM, 2011.\\n\\n8\\n\\n\\f[3] S. Duane, A. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid monte carlo. Physics Letter B,\\n\\n195(2):216\\u2013222, 1987.\\n\\n[4] J. Foulds, A. U. Asuncion, C. DuBois, C. T. Butts, and P. Smyth. A dynamic relational in\\ufb01nite feature\\n\\nmodel for longitudinal social networks. In AISTATS, 2011.\\n\\n[5] W. Fu, L. Song, and E. P. Xing. Dynamic mixed membership blockmodel for evolving networks.\\n\\nIn\\n\\nICML, 2009.\\n\\n[6] J. V. Gael, Y. W. Teh, , and Z. Ghahramani. The in\\ufb01nite factorial hidden markov model. In NIPS, 2009.\\n\\n[7] S. J. Gershman, P. I. Frazier, and D. M. Blei. Distance dependent in\\ufb01nite latent feature models.\\n\\narXiv:1110.5454, 2012.\\n\\n[8] Z. Ghahramani and M. I. Jordan. Factorial hidden markov models. Machine Learning, 29(2-3):245\\u2013273,\\n\\n1997.\\n\\n[9] F. Guo, S. Hanneke, W. Fu, and E. P. Xing. Recovering temporally rewiring networks: a model-based\\n\\napproach. In ICML, 2007.\\n\\n[10] S. Hanneke, W. Fu, and E. P. Xing. Discrete temporal models of social networks. Electron. J. Statist.,\\n\\n4:585\\u2013605, 2010.\\n\\n[11] C. Heaukulani and Z. Ghahramani. Dynamic probabilistic models for latent feature propagation in social\\n\\nnetworks. In ICML, 2013.\\n\\n[12] Q. Ho, L. Song, and E. P. Xing. Evolving cluster mixed-membership blockmodel for time-varying net-\\n\\nworks. In AISTATS, 2011.\\n\\n[13] P. D. Hoff, A. E. Raftery, and M. S. Handcock. Latent space approaches to social network analysis. JASA,\\n\\n97(460):1090 \\u2013 1098, 2002.\\n\\n[14] K. Ishiguro, T. Iwata, N. Ueda, and J. Tenenbaum. Dynamic in\\ufb01nite relational model for time-varying\\n\\nrelational data analysis. In NIPS, 2010.\\n\\n[15] S. Kairam, D. Wang, and J. Leskovec. The life and death of online groups: Predicting group growth and\\n\\nlongevity. In WSDM, 2012.\\n\\n[16] M. Kim and J. Leskovec. Modeling social networks with node attributes using the multiplicative attribute\\n\\ngraph model. In UAI, 2011.\\n\\n[17] M. Kim and J. Leskovec. Latent multi-group membership graph model. In ICML, 2012.\\n\\n[18] M. Kim and J. Leskovec. Multiplicative attribute graph model of real-world networks. Internet Mathe-\\n\\nmatics, 8(1-2):113\\u2013160, 2012.\\n\\n[19] M. Kim and J. Leskovec. Nonparametric multi-group membership model for dynamic networks.\\n\\narXiv:1311.2079, 2013.\\n\\n[20] J. R. Lloyd, P. Orbanz, Z. Ghahramani, and D. M. Roy. Random function priors for exchangeable arrays\\n\\nwith applications to graphs and relational data. In NIPS, 2012.\\n\\n[21] K. T. Miller, T. L. Grifths, and M. I. Jordan. Nonparametric latent feature models for link prediction. In\\n\\nNIPS, 2009.\\n\\n[22] M. M\\u00f8rup, M. N. Schmidt, and L. K. Hansen.\\n\\nIn\\ufb01nite multiple membership relational modeling for\\n\\ncomplex networks. In MLSP, 2011.\\n\\n[23] K. Palla, D. A. Knowles, and Z. Ghahramani. An in\\ufb01nite latent attribute model for network data.\\n\\nIn\\n\\nICML, 2012.\\n\\n[24] P. Sarkar and A. W. Moore. Dynamic social network analysis using latent space models. In NIPS, 2005.\\n\\n[25] J. Scott, R. Gass, J. Crowcroft, P. Hui, C. Diot, and A. Chaintreau. CRAWDAD data set cambridge/haggle\\n\\n(v. 2009-05-29), May 2009.\\n\\n[26] S. L. Scott. Bayesian methods for hidden markov models. JASA, 97(457):337\\u2013351, 2002.\\n\\n[27] T. A. B. Snijders, G. G. van de Bunt, and C. E. G. Steglich. Introduction to stochastic actor-based models\\n\\nfor network dynamics. Social Networks, 32(1):44\\u201360, 2010.\\n\\n[28] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su. Arnetminer: Extraction and mining of academic\\n\\nsocial networks. In KDD\\u201908, 2008.\\n\\n[29] J. Yang and J. Leskovec. Community-af\\ufb01liation graph model for overlapping community detection. In\\n\\nICDM, 2012.\\n\\n9\\n\\n\\f\",\n          \"Tangent Prop - A formalism for specifying \\nselected invariances in an adaptive network \\n\\nPatrice Simard \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nBernard Victorri \\nUniversite de Caen \\nCaen 14032 Cedex \\n\\nFrance \\n\\nYann Le Cun \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nJohn Denker \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nAbstract \\n\\nIn many machine learning applications, one has access, not only to training \\ndata, but also to some high-level a priori knowledge about the desired be(cid:173)\\nhavior of the system. For example, it is known in advance that the output \\nof a character recognizer should be invariant with respect to small spa(cid:173)\\ntial distortions of the input images (translations, rotations, scale changes, \\netcetera). \\nWe have implemented a scheme that allows a network to learn the deriva(cid:173)\\ntive of its outputs with respect to distortion operators of our choosing. \\nThis not only reduces the learning time and the amount of training data, \\nbut also provides a powerful language for specifying what generalizations \\nwe wish the network to perform. \\n\\n1 \\n\\nINTRODUCTION \\n\\nIn machine learning, one very often knows more about the function to be learned \\nthan just the training data. An interesting case is when certain directional deriva(cid:173)\\ntives of the desired function are known at certain points. For example, an image \\n895 \\n\\n\\f896 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nFigure 1: Top: Small rotations of an original digital image of the digit \\\"3\\\" (center). \\nMiddle: Representation of the effect of the rotation in the input vector space space \\n(assuming there are only 3 pixels). Bottom: Images obtained by moving along the \\ntangent to the transformation curve for the same original digital image (middle). \\n\\nrecognition system might need to be invariant with respect to small distortions of \\nthe input image such as translations, rotations, scalings, etc.; a speech recognition \\nsystem n.ight need to be invariant to time distortions or pitch shifts. \\nIn other \\nwords, the derivative of the system's output should be equal to zero when the input \\nis transformed in certain ways. \\n\\nGiven a large amount of training data and unlimited training time, the system \\ncould learn these invariances from the data alone, but this is often infeasible. The \\nlimitation on data can be overcome by training the system with additional data \\nobtained by distorting (translating, rotating, etc.) \\nthe original patterns (Baird, \\n1990). The top of Fig. 1 shows artificial data generated by rotating a digital image of \\nthe digit \\\"3\\\" (with the original in the center). This procedure, called the \\\"distortion \\nmodel\\\" , has two drawbacks. First, the user must choose the magnitude of distortion \\nand how many instances should be generated. Second, and more importantly, the \\ndistorted data is highly correlated with the original data. This makes traditional \\nlearning algorithms such as back propagation very inefficient. The distorted data \\ncarries only a very small incremental amount of information, since the distorted \\npatterns are not very different from the original ones. It may not be possible to \\nadjust the learning system so that learning the invariances proceeds at a reasonable \\nrate while learning the original points is non-divergent. \\n\\nThe key idea in this paper is that it is possible to directly learn the effect on \\nthe output of distorting the input, independently from learning the undistorted \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n897 \\n\\nF(x) \\n\\nF(x) \\n\\nx1 \\n\\nx2 \\n\\nx3 \\n\\nx4 \\n\\nx \\n\\nx1 \\n\\nx2 \\n\\nx3 \\n\\nx4 \\n\\nx \\n\\nFigure 2: Learning a given function (solid line) from a limited set of example (Xl \\nto X4). The fitted curves are shown in dotted line. Top: The only constraint is that \\nthe fitted curve goes through the examples. Bottom: The fitted curves not only \\ngoes through each examples but also its derivatives evaluated at the examples agree \\nwith the derivatives of the given function. \\n\\npatterns. When a pattern P is transformed (e.g. rotated) with a transformation \\ns that depends on one parameter a (e.g. the angle of the rotation), the set of all \\nthe transformed patterns S(P) = {sea, P) Va} is a one dimensional curve in the \\nvector space of the inputs (see Fig. 1). In certain cases, such as rotations of digital \\nimages, this curve must be made continuous using smoothing techniques, as will be \\nshown below. When the set of transformations is parameterized by n parameters \\nai (rotation, translation, scaling, etc.), S(P) is a manifold of at most n dimensions. \\nThe patterns in S(P) that are obtained through small transformations of P, i.e. \\nthe part of S( P) that is close to P, can be approximated by a plane tangent to \\nthe manifold S(P) at point P. Small transformations of P can be obtained by \\nadding to P a linear combination of vectors that span the tangent plane (tangent \\nvectors). The images at the bottom of Fig. 1 were obtained by that procedure. \\nMore importantly, the tangent vectors can be used to specify high order constraints \\non the function to be learned, as explained below. \\n\\nTo illustrate the method, consider the problem of learning a single-valued function \\nF from a limited set of examples. Fig. 2 (left) represents a simple case where the \\ndesired function F (solid line) is to be approximated by a function G (dotted line) \\nfrom four examples {(Xi, F(Xi))}i=1,2,3,4. As exemplified in the picture, the fitted \\nfunction G largely disagrees with the desired function F between the examples. If \\nthe functions F and G are assumed to be differentiable (which is generally the case), \\nthe approximation G can be greatly improved by requiring that G's derivatives \\nevaluated at the points {xd are equal to the derivatives of F at the same points \\n(Fig. 2 right). This result can be extended to multidimensional inputs. In this case, \\nwe can impose the equality of the derivatives of F and G in certain directions, not \\nnecessarily in all directions of the input space. \\nSuch constraints find immediate use in traditional learning problems. It is often the \\ncase that a priori knowledge is available on how the desired function varies with \\n\\n\\f898 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\npattern P \\n\\npattern P \\nrotated by ex \\n\\n-\\n\\ntangent \\nvector \\n\\n--\\n\\nFigure 3: How to compute a tangent vector for a given transformation (in this case \\na rotation). \\n\\nrespect to some transformations of the input. It is straightforward to derive the \\ncorresponding constraint on the directional derivatives of the fitted function G in \\nthe directions of the transformations (previously named tangent vectors). Typical \\nexamples can be found in pattern recognition where the desired classification func(cid:173)\\ntion is known to be invariant with respect to some transformation of the input such \\nas translation, rotation, scaling, etc., in other words, the directional derivatives of \\nthe classification function in the directions of these transformations is zero. \\n\\n2 \\n\\nIMPLEMENTATION \\n\\nThe implementation can be divided into two parts. The first part consists in com(cid:173)\\nputing the tangent vectors. This part is independent from the learning algorithm \\nused subsequently. The second part consists in modifying the learning algorithm \\n(for instance backprop) to incorporate the information about the tangent vectors. \\nPart I: Let x be an input pattern and s be a transformation operator acting \\non the input space and depending on a parameter a. If s is a rotation operator \\nfor instance, then s( a, x) denotes the input x rotated by the angle a. We will \\nrequire that the transformation operator s be differentiable with respect to a and \\nx, and that s(O, x) = x. The tangent vector is by definition 8s(a, x)/8a. It can be \\napproximated by a finite difference, as shown in Fig. 3. In the figure, the input space \\nis a 16 by 16 pixel image and the patterns are images of handwritten digits. The \\ntransformations considered are rotations of the digit images. The tangent vector \\nis obtained in two steps. First the image is rotated by an infinitesimal amount a. \\nThis is done by computing the rotated coordinates of each pixel and interpolating \\nthe gray level values at the new coordinates. This operation can be advantageously \\ncombined with some smoothing using a convolution. A convolution with a Gaussian \\nprovides an efficient interpolation scheme in O(nm) multiply-adds, where nand m \\nare the (gaussian) kernel and image sizes respectively. The next step is to subtract \\n(pixel by pixel) the rotated image from the original image and to divide the result \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n899 \\n\\nby the scalar 0 (see Fig. 3). If Ie types of transformations are considered, there \\nwill be Ie different tangent vectors per pattern. For most algorithms, these do not \\nrequire any storage space since they can be generated as needed from the original \\npattern at negligible cost. \\nPart IT: Tangent prop is an extension of the backpropagation algorithm, allowing \\nit to learn directional derivatives. Other algorithms such as radial basis functions \\ncan be extended in a similar fashion. \\n\\nTo implement our idea, we will modify the usual weight-update rule: \\nis replaced with ~w = -7] ow (E + J.tEr) \\n\\noE \\n~w = -7] ow \\n\\n0 \\n\\n(1) \\n\\nwhere 7] is the learning rate, E the usual objective function, Er an additional objec(cid:173)\\ntive function (a regularizer) that measures the discrepancy between the actual and \\ndesired directional derivatives in the directions of some selected transformations, \\nand J.t is a weighting coefficient. \\nLet x be an input pattern, y = G(x) be the input-output function of the network. \\nThe regularizer Er is of the form \\n\\nwhere Er(x) is \\n\\nEr(x) \\n\\n:e e trainingset \\n\\n(2) \\n\\nHere, Ki(x) is the desired directional derivative of G in the direction induced by \\ntransformation Si applied to pattern x. The second term in the norm symbol is the \\nactual directional derivative, which can be rewritten as \\n\\n= G'{x). OSi(O, x) \\n\\n00 \\n\\n0=0 \\n\\n0=0 \\n\\nwhere G'(x) is the Jacobian of G for pattern x, and OSi(O, x)Joo is the tangent \\nvector associated to transformation Si as described in Part I. Multiplying the tangent \\nvector by the Jacobian involves one forward propagation through a \\\"linearized\\\" \\nversion of the network. In the special case where local invariance with respect to \\nthe Si'S is desired, Ki(x) is simply set to o. \\nComposition of transformations: The theory of Lie groups (Gilmore, 1974) \\nensures that compositions of local (small) transformations Si correspond to linear \\ncombinations of the corresponding tangent vectors (the local transformations Si \\nhave a structure of Lie algebra). Consequently, if Er{x) = 0 is verified, the network \\nderivative in the direction of a linear combination of the tangent vectors is equal \\nto the same linear combination of the desired derivatives. In other words if the \\nnetwork is successfully trained to be locally invariant with respect to, say, horizontal \\ntranslation and vertical translations, it will be invariant with respect to compositions \\nthereof. \\nWe have derived and implemented an efficient algorithm, \\\"tangent prop\\\" , for per(cid:173)\\nforming the weight update (Eq. 1). It is analogous to ordinary backpropagation, \\n\\n\\f900 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nW'+l \\n\\nIti \\n\\nW l+1 \\n\\nIti \\n\\ne: l \\n\\nb'.-l , \\n\\nx\\u00b7 , \\n'-I \\n\\nNetwork \\n\\nj3J-1 \\n\\ne;-I \\nJacobian nework \\n\\nFigure 4: forward propagated variables (a, x, a, e), and backward propagated vari(cid:173)\\nables (b, y, p, t/J) in the regular network (roman symbols) and the Jacobian (lin(cid:173)\\nearized) network (greek symbols) \\n\\nbut in addition to propagating neuron activations, it also propagates the tangent \\nvectors. The equations can be easily derived from Fig. 4. \\nForward propagation: \\n\\na~ = ~ wL x'.-l \\nI, , \\n\\u2022 \\n\\nL...J \\ni \\n\\nx~ = u(aD \\n\\nTangent forward propagation: \\n\\n, _ ~ , ~'-1 \\nai - L...J wW\\\"i \\n\\ni \\n\\ne! = u'(a~)a~ \\n\\nTangent gradient backpropagation: \\n\\n(31 - ~ w'+1.I.l+1 \\ni - L...J \\nIt \\n\\nIti \\u00a5lit \\n\\nGradient backpropagation: \\n\\nb' - ~ w1+ 1yl+1 \\ni - L...J \\nIt \\n\\nIti \\n\\nIt \\n\\nWeight update: \\n\\n8[E(W, Up) + I'Er (W, Up, Tp)] _ 1-1 , + ~'-l.I.' \\n\\u00a5Ii \\n\\n- Xi Yi \\n\\nI'\\\\oi \\n\\nw\\u00b7\\u00b7 I, \\n8 ' \\n\\n(3) \\n\\n(4) \\n\\n(5) \\n\\n(6) \\n\\n(7) \\n\\n\\fTangent Prop--A formalism for specifying selected invariances in an adaptive network \\n\\n901 \\n\\n60 \\n\\n50 \\n\\n%Erroron \\nthe test set \\n\\n20 \\n\\n10 \\n\\n160 \\n\\n320 \\n\\nTraining set size \\n\\nFigure 5: Generalization performance curve as a function of the training set size for \\nthe tangent prop and the backprop algorithms \\n\\nThe regularization parameter jJ is tremendously important, because it determines \\nthe tradeoff between minimizing the usual objective function and minimizing the \\ndirectional derivative error. \\n\\n3 RESULTS \\n\\nTwo experiments illustrate the advantages of tangent prop. The first experiment \\nis a classification task, using a small (linearly separable) set of 480 binarized hand(cid:173)\\nwritten digit. The training sets consist of 10, 20, 40, 80, 160 or 320 patterns, and \\nthe training set contains the remaining 160 patterns. The patterns are smoothed \\nusing a gaussian kernel with standard deviation of one half pixel. For each of the \\ntraining set patterns, the tangent vectors for horizontal and vertical translation \\nare computed. The network has two hidden layers with locally connected shared \\nweights, and one output layer with 10 units (5194 connections, 1060 free parame(cid:173)\\nters) (Le Cun, 1989). The generalization performance as a function of the training \\nset size for traditional backprop and tangent prop are compared in Fig. 5. We have \\nconducted additional experiments in which we implemented not only translations \\nbut also rotations, expansions and hyperbolic deformations. This set of 6 gener(cid:173)\\nators is a basis for all linear transformations of coordinates for two dimensional \\nimages. It is straightforward to implement other generators including gray-Ievel(cid:173)\\nshifting, \\\"smooth\\\" segmentation, local continuous coordinate transformations and \\nindependent image segment transformations. \\n\\nThe next experiment is designed to show that in applications where data is highly \\n\\n\\f902 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nAv\\\"ge NMSE VI 1ge \\n\\nA-. NMSE VI. \\n\\n0.15 \\n\\n0.1 \\n\\n.15 \\n\\n.1 \\n\\no \\no 1000 2000 3000 4000 5000 6000 7000 8000 0000 10000 \\n\\noL-~~==~~=;~==+=~~~ \\n1000 2000 3000 4000 5000 6000 7000 8000 0000 10000 \\n0 \\n\\n-\\n\\n\\\" \\n\\n..... \\n\\n15 \\n\\no \\n\\n-0.5 \\n\\n-1 \\n\\n..... \\n\\n15 -\\n\\n\\\" \\n\\n0 \\n\\n-.5 \\n\\n-1 \\n\\n-1 .5 +--_+_-_--+_-_+_-_-_ \\n\\n-1.5 +--_+_-_--+--_+_-_-__t \\n\\n-1 .5 \\n\\n-1 \\n\\n1.5 \\n\\n-1.5 \\n\\n-1 \\n\\n0 \\n\\n0.5 \\n\\n-0.5 \\nDistortion model \\n\\no \\n\\n.5 \\n\\n- .5 \\nTangent prop \\n\\n1.5 \\n\\nFigure 6: Comparison of the distortion model (left column) and tangent prop (right \\ncolumn). The top row gives the learning curves (error versus number of sweeps \\nthrough the training set). The bottom row gives the final input-output function of \\nthe network; the dashed line is the result for unadorned back prop. \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n903 \\n\\ncorrelated, tangent prop yields a large speed advantage. Since the distortion model \\nimplies adding lots of highly correlated data, the advantage of tangent prop over \\nthe distortion model becomes clear. \\nThe task is to approximate a function that has plateaus at three locations. We want \\nto enforce local invariance near each of the training points (Fig. 6, bottom). The \\nnetwork has one input unit, 20 hidden units and one output unit. Two strategies are \\npossible: either generate a small set of training point covering each of the plateaus \\n(open squares on Fig. 6 bottom), or generate one training point for each plateau \\n(closed squares), and enforce local invariance around them (by setting the desired \\nderivative to 0). The training set of the former method is used as a measure the \\nperformance for both methods. All parameters were adjusted for approximately \\noptimal performance in all cases. The learning curves for both models are shown in \\nFig. 6 (top). Each sweep through the training set for tangent prop is a little faster \\nsince it requires only 6 forward propagations, while it requires 9 in the distortion \\nmodel. As can be seen, stable performance is achieved after 1300 sweeps for the \\ntangent prop, versus 8000 for the distortion model. The overall speedup is therefore \\nabout 10. \\nTangent prop in this example can take advantage of a very large regularization term. \\nThe distortion model is at a disadvantage because the only parameter that effec(cid:173)\\ntively controls the amount of regularization is the magnitude of the distortions, and \\nthis cannot be increased to large values because the right answer is only invariant \\nunder small distortions. \\n\\n4 CONCLUSIONS \\n\\nWhen a priori information about invariances exists, this information must be made \\navailable to the adaptive system. There are several ways of doing this, including the \\ndistortion model and tangent prop. The latter may be much more efficient in some \\napplications, and it permits separate control of the emphasis and learning rate for \\nthe invariances, relative to the original training data points. Training a system to \\nhave zero derivatives in some directions is a powerful tool to express invariances to \\ntransformations of our choosing. Tests of this procedure on large-scale applications \\n(handwritten zipcode recognition) are in progress. \\n\\nReferences \\n\\nBaird, H. S. (1990). Document Image Defect Models. In IAPR 1990 Workshop on \\n\\nSytactic and Structural Pattern Recognition, pages 38-46, Murray Hill, NJ. \\n\\nGilmore, R. (1974). Lie Groups, Lie Algebras and some of their Applications. Wiley, \\n\\nNew York. \\n\\nLe Cun, Y. (1989) . Generalization and Network Design Strategies. In Pfeifer, R., \\nSchreter, Z., Fogelman, F., and Steels, L., editors, Connectionism in Perspec(cid:173)\\ntive, Zurich, Switzerland. Elsevier. an extended version was published as a \\ntechnical report of the University of Toronto. \\n\\n\\f\",\n          \"Minimizing  Statistical Bias with Queries \\n\\nDavid A.  Cohn \\n\\nAdaptive Systems Group \\n\\nHarlequin,  Inc. \\n\\nOne  Cambridge Center \\nCambridge,  MA  02142 \\ncOhnCharlequin.com \\n\\nAbstract \\n\\nI describe  a  querying criterion that attempts to minimize the error \\nof a  learner  by  minimizing its estimated squared  bias.  I  describe \\nexperiments  with  locally-weighted  regression  on  two  simple prob(cid:173)\\nlems,  and observe  that this  \\\"bias-only\\\"  approach  outperforms the \\nmore  common  \\\"variance-only\\\"  exploration  approach,  even  in  the \\npresence  of noise. \\n\\n1 \\n\\nINTRODUCTION \\n\\nIn recent  years, there has been an explosion of interest in \\\"active\\\"  machine learning \\nsystems.  These  are  learning  systems  that  make  queries,  or  perform  experiments \\nto  gather data that  are expected  to maximize performance.  When  compared with \\n\\\"passive\\\"  learning  systems,  which  accept  given,  or  randomly  drawn  data,  active \\nlearners have demonstrated significant decreases  in the amount of data required  to \\nachieve equivalent performance.  In industrial applications,  where  each  experiment \\nmay take  days  to  perform  and  cost  thousands  of dollars,  a  method  for  optimally \\nselecting  these  points would offer enormous savings in time and  money. \\nAn  active  learning system  will  typically attempt to select  data that  will  minimize \\nits  predictive  error.  This  error  can  be  decomposed  into  bias  and  variance  terms. \\nMost  research  in selecting  optimal actions or  queries  has  assumed  that the learner \\nis  approximately unbiased,  and that to minimize learner error,  variance is  the only \\nthing  to  minimize  (e.g.  Fedorov  [1972]'  MacKay  [1992]'  Cohn  [1996],  Cohn  et  al., \\n[1996],  Paass  [1995]).  In  practice,  however,  there  are very  few  problems for  which \\nwe have unbiased learners.  Frequently, bias constitutes a large portion of a learner's \\nerror;  if the learner is deterministic and the data are noise-free, then bias is the  only \\nsource  of error.  Note  that the bias  term here  is  a  statistical bias,  distinct from  the \\ninductive  bias  discussed  in some  machine  learning  research  [Dietterich  and  Kong, \\n1995]. \\n\\n\\f418 \\n\\nD.A. Cohn \\n\\nIn this paper I describe an algorithm which selects actions/ queries designed to mini(cid:173)\\nmize the bias of a locally weighted regression-based  learner.  Empirically, \\\"variance(cid:173)\\nminimizing\\\" strategies which ignore bias seem to perform well, even in cases  where, \\nstrictly speaking,  there is  no  variance  to  minimize.  In  the  tasks  considered  in  this \\npaper,  the  bias-minimizing strategy  consistently  outperforms  variance  minimiza(cid:173)\\ntion, even in  the presence  of noise. \\n\\n1.1  BIAS  AND  VARIANCE \\n\\nLet us  begin  by defining P(x, y)  to be the unknown joint distribution over  x and y, \\nand  P( x)  to  be  the  known  marginal distribution  of x  (commonly called  the  input \\ndistribution).  We  denote  the  learner's  output  on input  x,  given  training set  D  as \\ny(x; D).  We  can  then  write the expected  error of the learner as \\n\\n1 E  [(y(x;D) - y(x))2Ix] P(x)dx, \\n\\n(1) \\n\\nwhere E[\\u00b7] denotes the expectation over P and over training sets D.  The expectation \\ninside the integral may be  decomposed as follows  (Geman et al. , 1992): \\n\\nE  [(y(x;D) - y(x))2Ix] \\n\\nE  [(y(x) - E[ylx]?] \\n\\n(2) \\n\\n+ (Ev [y(x; D)] - E[ylx])2 \\n\\n+Ev [(y(x;D) - Ev[y(x;D)])2] \\n\\nwhere Ev [.] denotes the expectation over training sets.  The first  term in Equation 2 \\nis the variance of y given x - it is the noise in the distribution, and does  not depend \\non our learner or how the training data are chosen.  The second term is the learner's \\nsquared bias, and the third is its variance; these last two terms comprise the expected \\nsquared error of the learner  with  respect  to the regression  function  E[Ylx]. \\nMost  research  in  active  learning  assumes  that  the  second  term  of Equation  2  is \\napproximately zero,  that  is,  that  the  learner  is  unbiased.  If this  is  the  case,  then \\none may concentrate on selecting data so  as to minimize the variance of the learner. \\nAlthough this  \\\"all-variance\\\" approach is optimal when the learner is  unbiased, truly \\nunbiased  learners  are  rare.  Even  when  the  learner's  representation  class  is  able \\nto  match  the  target  function  exactly,  bias is  generally  introduced  by  the  learning \\nalgorithm  and  learning  parameters.  From  the  Bayesian  perspective,  a  learner  is \\nonly unbiased  if its  priors are  exactly  correct. \\nThe optimal choice  of query would,  of course, minimize  both  bias and variance,  but \\nI leave that for future work.  For the purposes of this paper, I will only be concerned \\nwith  selecting  queries  that  are  expected  to  minimize  learner  bias.  This  approach \\nis  justified  in  cases  where  noise  is  believed  to  be  only  a  small  component  of the \\nlearner's  error.  If the  learner  is  deterministic  and  there  is  no  noise,  then  strictly \\nspeaking, there  is  no error  due  to  variance -\\nall  the error  must be  due  to learner \\nbias.  In cases with non-determinism or noise, all-bias minimization, like all-variance \\nminimization, becomes  an approximation of the optimal approach. \\n\\nThe learning model discussed  in this paper is  a  form of locally  weighted  regression \\n(LWR)  [Cleveland et  al.,  1988],  which  has  been  used  in  difficult  machine  learning \\ntasks,  notably  the  \\\"robot  juggler\\\"  of Schaal  and  Atkeson  [1994].  Previous  work \\n[Cohn et al.,  1996]  discussed  all-variance query selection for  LWR; in the remainder \\nof this paper, I describe  a method for  performing all-bias query selection.  Section 2 \\ndescribes the criterion that must be optimized for all-bias query selection.  Section 3 \\ndescribes  the  locally  weighted  regression  learner  used  in  this  paper  and  describes \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n419 \\n\\nhow  the  all-bias criterion  may be  computed for  it .  Section  4  describes  the  results \\nof experiments using this criterion on several simple domains.  Directions for future \\nwork  are discussed  in  Section 5. \\n\\n2  ALL-BIAS  QUERY  SELECTION \\n\\nLet  us  assume for  the moment that we  have  a source of noise-free examples (Xi, Yi) \\nand  a  deterministic learner  which,  given  input  X,  outputs estimate Y(X).l  Let  us \\nalso  assume  that  we  have  an  accurate estimate of the  bias  of y which  can  be  used \\nto estimate  the  true  function  y(x)  =  y(x)  - bias(x).  We  will  break  these  rather \\nstrong assumptions of noise-free examples and accurate bias estimates in Section 4, \\nbut they  are useful for  deriving  the theoretical  approach described  below. \\n\\nGiven  an  accurate  bias estimate,  we  must force  the  biased  estimator into the  best \\napproximation of y(x)  with  the fewest  number of examples.  This,  in effect,  trans(cid:173)\\nforms  the  query  selection  problem  into  an  example filter  problem  similar  to  that \\nstudied  by  Plutowski  and  White  [1993]  for  neural  networks.  Below,  I  derive  this \\ncriterion for  estimating the change  in error at  X  given  a  new  queried  example at x. \\nSince  we  have  (temporarily)  assumed  a  deterministic  learner  and  noise-free  data, \\nthe expected  error in  Equation 2 simplifies to: \\n\\nE  [(Y( X; 'D)  - y( x))2Ix, 'D] \\n\\n(Y(x; 'D)  - y(x))2 \\n\\n(3) \\n\\nWe  want to select  a new  x such that when we  add (x, f)),  the resulting squared bias \\nis  minimized: \\n\\n(Y'  - y? ==  (y(x; 'D U (x, f)))  - y(x))2 . \\n\\n(4) \\nI will, for the remainder of the paper, use the  \\\"'\\\"  to indicate estimates based on the \\ninitial training set  plus  the  additional example  (x, y).  To  minimize  Expression  4, \\nwe  need  to  compute  how  a  query  at  x will  change  the  learner's  bias  at  x.  If we \\nassume  that  we  know  the  input  distribution,2  then  we  can  integrate  this  change \\nover  the  entire  domain  (using  Monte  Carlo  procedures)  to  estimate  the  resulting \\naverage  change,  and select  a  x such  that  the  expected  squared  bias  is  minimized. \\nDefining bias ==  y - y and f:,.y  ==  y'  - y, we  can  write the new  squared  bias as: \\n\\nbias,2 \\n\\n(y'  - y)2  =  (Y + f:,.y  _ y)2 \\nf:,.y2  + 2f:,.y . bias + bias2 \\n\\n(5) \\nNote  that  since  bias  as  defined  here  is  independent  of x,  minimizing  the  bias  is \\nequivalent to minimizing f:,.y2  + 2f:,.y . bias. \\nThe estimate of bias'  tells  us  how much our bias will change for  a given x. We may \\noptimize this value over x in one of a number of ways.  In low dimensional spaces,  it \\nis often sufficient to consider a set of \\\"candidate\\\" x and select the one promising the \\nsmallest resulting  error.  In  higher  dimensional spaces,  it  is  often  more efficient  to \\nsearch  for  an optimal x with  a  response  surface  technique  [Box  and  Draper, 1987], \\nor hill climb on  abias,2 / ax. \\nEstimates  of bias  and  f:,.y  depend  on  the  specific  learning  model  being  used.  In \\nSection 3, I describe a locally weighted regression model, and show how differentiable \\nestimates of bias  and f:,.y  may be  computed for  it. \\n\\n1 For  clarity,  I  will  drop  the  argument  :z;  except  where  required  for  disambiguation.  I \\n\\nwill  also  denote only  the univariate  case;  the results  apply  in  higher  dimensions  as  well. \\n2This assumption is  contrary to the assumption norma.lly  made in some forms of learn(cid:173)\\n\\ning,  e.g.  PAC-learning,  but it is  appropriate in  many  domains. \\n\\n\\f420 \\n\\nD.  A.  Cohn \\n\\n2.1  AN  ASIDE:  WHY  NOT JUST USE Y - Mas? \\n\\nIf we  have  an accurate  bias estimate, it is  reasonable to ask  why  we  do  not simply \\nuse  the  corrected  y - C;;;S  as  our  predictor.  The  answer  has  two  parts,  the  first \\nof  which  is  that  for  most  learners,  there  are  no  perfect  bias  estimators  -\\nthey \\nintroduce their own  bias and  variance,  which  must  be  addressed  in data selection. \\nSecond,  we  can  define  a  composite learner Ye  ==  Y - C:;;;S.  Given  a random training \\nsample  then,  we  would  expect  Ye  to  outperform  y.  However,  there  is  no  obvious \\nway  to select  data for  this composite learner other than selecting  to maximize the \\nperformance  of its  two  components.  In  our  case,  the  second  component  (the  bias \\nestimate)  is  non-analytic,  which  leaves  us  selecting  data  so  as  to  maximize  the \\nperformance of the  first  component  (the uncorrected  estimator).  We  are  now  back \\nto  our  original  problem:  we  can  select  data so  as  to  minimize either  the  bias  or \\nvariance of the uncorrected  LWR-based learner.  Since the purpose of the correction \\nis to give an unbiased estimator, intuition suggests that variance minimization would \\nbe the more sensible route in this  case.  Empirically, this approach does  not appear \\nto yield  any  benefit  over  uncorrected  variance minimization (see  Figure  1). \\n\\n3  LOCALLY WEIGHTED REGRESSION \\n\\nThe type  of learner  I  consider here  is  a form  of locally weighted  regression  (LWR) \\nthat is  a slight variation on  the  LOESS  model of Cleveland et  al.  [1988]  (see  Cohn \\net al., [1996]  for details).  The LOESS  model performs a linear regression  on points \\nin  the  data set,  weighted  by  a  kernel  centered  at  x.  The kernel  shape  is  a  design \\nparameter:  the original LOESS  model uses  a  \\\"tricubic\\\"  kernel;  in my experiments \\nI  use  the more common Gaussian \\n\\nwhere Ie  is a smoothing parameter.  For brevity, I will drop the argument x for  hi(x), \\nand define  n  = 2:i  hi.  We  can then  write  the weighted  means and  covariances  as: \\n\\n\\\"\\\"  Xi \\n, \\nn \\n. \\n\\nJ.l:r;  = L..J hi - ,  \\nJ.ly  = L h,-, \\n\\nYi \\nn \\n\\n, \\n. \\n\\n\\\"\\\" \\n\\nU:r;y  =  L..J hi \\n\\n, \\n. \\n\\n(Xi  - X)(Yi  - J.ly) \\n\\nn \\n\\n. \\n\\nWe use these means and covariances to produce an estimate Y at the x  around which \\nthe kernel  is  centered,  with  a  confidence  term in  the form of a  variance estimate: \\n\\nIn  all the experiments  discussed  in  this paper,  the smoothing parameter Ie  was  set \\nso  as  to minimize u2. \\nThe  low  cost  of incorporating  new  training  examples  makes  this  form  of locally \\nweighted regression  appealing for  learning systems which must operate in real time, \\nor with time-varying target functions  (e.g.  [Schaal and Atkeson  1994]). \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n421 \\n\\nI \\n\\nI \\nY \\n\\n) \\n\\nA \\n\\nA \\n\\nA  I \\n\\nA \\n\\n3.1  COMPUTING D..y  FOR LWR \\nIf we  know  what  new  point  (x, y)  we're  going  to  add,  computing D..y  for  LWR  is \\nstraightforward.  Defining h as  the  weight  given to x,  and n as  n + h we  can write \\n~y  =  y  - y  =  J.L  + -\\n\\nx  - J.Lx \\n\\nh (Y  ___ J.Ly)  _  uxy (x _  J.Lx)  + (x _  n~x _  ~x) . nuXY_ + h . ~x -:xKii - J.Ly) \\n\\nU xy ( \\nU/2 \\nx \\n\\nU xy ( \\n-\\nu2 \\nx \\n\\nn \\n\\nnu;+h\\u00b7(x-J.Lx)2 \\nNote  that computing D..y  requires  us  to know both the x and y of the new  point .  In \\npractice,  we only know x.  If we  assume, however,  that we  can estimate the learner's \\nbias  at  any  x,  then  we  can  also estimate  the  unknown  value  y ~ y(x)  - bias(x) . \\nBelow,  I  consider  how  to compute the bias  estimate. \\n\\nn \\n\\nn \\n\\nI  ) \\nx - J.L \\nx \\n\\n- J.L \\ny \\n\\n-\\n\\nu; \\n\\n3.2  ESTIMATING  BIAS  FOR LWR \\n\\nThe most common technique for estimating bias is  cross-validation .  Standard cross(cid:173)\\nvalidation however, only gives estimates of the  bias  at our specific  training points , \\nwhich  are  usually combined  to form  an  average  bias estimate.  This is  sufficient  if \\none  assumes  that the  training distribution is  representative  of the  test  distribution \\n(which  it  isn't  in  query  learning)  and  if one  is  content  to just  estimate  the  bias \\nwhere  one  already has  training data (which  we  can't be). \\nIn the query selection  problem, we  must be  able to estimate the bias  at all possible \\nx.  Box  and  Draper  [1987]  suggest  fitting  a  higher  order  model and measuring the \\ndifference.  For  the  experiments  described  in  this  paper,  this  method yielded  poor \\nresults; two other bias-estimation techniques,  however, performed very  well. \\n\\nOne  method  of estimating  bias  is  by  bootstrapping  the  residuals  of  the  training \\npoints.  One produces a  \\\"bootstrap sample\\\" of the learner's residuals on the training \\ndata, and adds them to the original predictions to create a synthetic training set .  By \\naveraging  predictions  over  a  number of bootstrapped  training sets  and  comparing \\nthe average prediction with that of the original predictor, one arrives at a first-order \\nbootstrap estimate of the predictor's bias [Connor 1993; Efron and Tibshirani, 1993] . \\nIt is  known  that this  estimate is  itself biased  towards  zero;  a  standard heuristic  is \\nto divide the estimate by  0.632  [Efron,  1983]. \\nAnother method of estimating bias of a learner is  by fitting  its own cross-validated \\nresiduals.  We  first  compute the cross-validated residuals  on  the training examples. \\nThese  produce  estimates  of the  learner's  bias  at  each  of the  training  points.  We \\ncan then  use  these  residuals  as  training examples for  another  learner  (again  LWR) \\nto produce estimates of what the cross-validated error would be  in places  where  we \\ndon't have  training data. \\n\\n4  EMPIRICAL  RESULTS \\n\\nIn  the  previous  two  sections,  I  have  explained  how  having  an  estimate of D..y  and \\nbias  for  a  learner  allows  one  to  compute  the  learner's  change  in  bias  given  a  new \\nquery,  and  have  shown  how  these  estimates  may be  computed  for  a  learner  that \\nuses  locally weighted regression.  Here,  I apply these  results to two simple problems \\nand  demonstrate  that  they  may  actually  be  used  to  select  queries  that  minimize \\nthe statistical bias (and the error)  of the learner.  The problems involve learning the \\nkinematics  of a  planar  two-jointed  robot  arm:  given  the  shoulder  and elbow joint \\nangles, the learner must predict  the  tip position. \\n\\n\\f422 \\n\\n4.1  BIAS  ESTIMATES \\n\\nD.A. Cohn \\n\\nI tested the accuracy of the two bias estimators by observing their correlations on 64 \\nreference  inputs, given 100 random training examples from the planar arm problem. \\nThe  bias estimates had  a  correlation  with  actual biases  of 0.852  for  the bootstrap \\nmethod, and 0.871  for  the  cross-validation method. \\n\\n4.2  BIAS  MINIMIZATION \\n\\nI ran two sets of experiments using the bias-minimizing criterion in conjunction with \\nthe  bias  estimation technique  of the  previous  section  on  the  planar arm  problem. \\nThe bias minimization criterion was  used  as follows:  At each time step, the learner \\nwas  given  a  set  of 64  randomly chosen  candidate  queries  and  64  uniformly chosen \\nreference  points.  It evaluated  E' (x)  for  each  reference  point  given  each  candidate \\npoint and selected  for  its next  query  the candidate point with the smallest average \\nE' (x) over the reference  points.  I compared the bias-minimizing strategy (using the \\ncross-validation and bootstrap estimation techniques)  against random sampling and \\nthe  variance-minimizing strategy  discussed  in  Cohn  et  al.  [1996].  On  a  Sparc  10, \\nwith m training examples, the  average evaluation times per candidate per reference \\npoint were  58 + 0.16m J.lseconds  for  the variance criterion, 65 + 0.53m J.lseconds  for \\nthe cross-validation-based bias criterion, and 83 + 3. 7m J.lseconds  for  the bootstrap(cid:173)\\nbased  bias criterion  (with  20x resampling) . \\nTo test  whether the  bias-only assumption was robust  against the presence  of noise, \\n1 % Gaussian  noise  was  added  to  the  input  values  of the  training  data  in  all  ex(cid:173)\\nperiments.  This simulates noisy  position effectors  on  the arm , and  results  in  non(cid:173)\\nGaussian noise  in  the output coordinate  system. \\n\\nIn  the  first  series  of experiments,  the  candidate  shoulder  and  elbow  joint  angles \\nwere  drawn  uniformly over  (U[O, 271\\\"],  U[O,  71\\\")) .  In  unconstrained  domains like  this, \\nrandom sampling is  a fairly good default  strategy.  The bias minimization strategies \\nstill  significantly  outperform  both  random  sampling  and  the  variance  minimizing \\nstrategy in these  experiments (see  Figure  1). \\n\\n-1 \\n\\n10 \\n\\ng \\n'\\\" 'il ,0-2 \\n:a \\n~ \\nc: \\n~10  .  random \\n\\n-3 \\n\\n' '\\\\ \\n\\n\\\".'~ \\n\\nvariance-min \\n-\\no  cross-val-min \\n~ x  bootstrap-min \\n200 \\n\\n100 \\n\\n10  0 \\n\\n300 \\n\\ntrainlno set size \\n\\nI, \\n\\\\\\\\ \\n--\\n\\n1 \\n10 \\n\\ng  0 \\n\\n\\\"'10 \\n\\n}1O-1 \\n~  -2 \\n\\n,- -\\n\\n.:  ~~&e-.!)jni(llIZI~  , \\no \\n\\n10 \\n10-3  ~  ~~~~rmiWngar- iOlmizing \\n400 \\n\\n300 \\n\\n200 \\n\\n1 00 \\n\\ntrainino set size \\n\\nIheta 1 \\n\\n(left)  MSE  as  a  function  of number of noisy  training examples for  the \\nFigure  1: \\nunconstrained  arm  problem.  Errors  are  averaged  over  10  runs  for  the  bootstrap \\nmethod and 15  runs for  all others.  One run with the cross-validation-based method \\nwas  excluded  when  k  failed  to  converge  to  a  reasonable  value.  (center)  MSE  as \\na  function  of number of noisy  training examples for  the  constrained  arm problem . \\nThe bias correction strategy discussed in Section 2.1  does no better than the uncor(cid:173)\\nrected  variance-minimizing strategy,  and  much  worse  than  the  bias-minimization \\nstrategy.  (right)  Sample  exploration  trajectory  in  joint-space  for  the  constrained \\narm problem , explored  according  to the bias minimizing criterion. \\n\\nIn the second series of experiments, candidates were  drawn uniformly from a region \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n423 \\n\\nlocal to  the previously  selected  query:  (01  \\u00b1 0.217\\\", O2  \\u00b1 0.117\\\").  This corresponds  to \\nrestricting  the  arm  to local  motions.  In  a  constrained  problem such  as  this,  ran(cid:173)\\ndom  sampling  is  a  poor  strategy;  both  the  bias  and  variance-reducing  strategies \\noutperform it at least  an order of magnitude.  Further, the  bias-minimization strat(cid:173)\\negy  outperforms variance minimization by a large  margin (Figure 1).  Figure  1 also \\nshows  an  exploration  trajectory  produced  by  pursuing  the  bias-minimizing crite(cid:173)\\nrion.  It is  noteworthy that, although the implementation in this case  was a  greedy \\n(one-step)  minimization, the trajectory results  in globally good exploration. \\n\\n5  DISCUSSION \\n\\nI  have argued  in  this paper  that, in many situations, selecting  queries  to minimize \\nlearner bias is an appropriate and effective strategy for  active learning.  I have given \\nempirical  evidence  that,  with  a  LWR-based  learner  and  the  examples  considered \\nhere,  the strategy is effective  even  in the presence  of noise. \\n\\nBeyond  minimizing either  bias  or  variance,  an  important next  step  is  to explicitly \\nminimize  them  together .  The  bootstrap-based  estimate should  facilitate  this,  as \\nit produces  a  complementary variance estimate with little additional computation. \\nBy optimizing over both criteria simultaneously, we expect to derive a criterion that \\nthat, in  terms of statistics,  is  truly optimal for  selecting  queries. \\n\\nREFERENCES \\nBox,  G.,  &  Draper, N.  (1987).  Empirical model-building  and  response  surfaces, \\nWiley,  New  York. \\nCleveland,  W.,  Devlin,  S.,  &  Grosse,  E.  (1988) .  Regression  by  local fitting. \\nJournal  of Econometrics,  37, 87-114. \\nCohn,  D.  (1996)  Neural  network  exploration  using  optimal  experiment  design. \\nNeural Networks,  9(6):1071-1083. \\nCohn,  D.,  Ghahramani,  Z.,  &  Jordan,  M.  (1996) .  Active  learning  with sta(cid:173)\\ntistical models.  Journal  of Artificial Inteligence  Research 4:129-145 . \\nConnor, J. (1993).  Bootstrap Methods in Neural Network Time Series  Prediction. \\nIn  J .  Alspector  et  al.,  eds.,  Proc.  of the  Int.  Workshop  on  Applications  of Neural \\nNetworks  to  Telecommunications,  Lawrence  Erlbaum, Hillsdale,  N.J. \\nDietterich,  T.,  &  Kong,  E.  (1995) .  Error-correcting  output  coding  corrects \\nbias  and  variance.  In  S.  Prieditis  and  S.  Russell,  eds.,  Proceedings  of the  12th \\nInternational  Conference  on  Machine  Learning. \\nEfron, B. (1983) Estimating the error rate of a prediction rule:  some improvements \\non cross-validation.  J.  Amer.  Statist.  Assoc.  78:316-331. \\nEfron, B.  &  Tibshirani, R.  (1993).  An introduction  to  the  bootstrap.  Chapman \\n&  Hall,  New  York . \\nFedorov, V.  (1972).  Theory  of Optimal Experiments.  Academic Press,  New  York. \\nGeman, S.,  Bienenstock, E.,  &  Doursat, R.  (1992).  Neural  networks and the \\nbias/variance dilemma.  Neural  Computation,  4,  1-58. \\nMacKay,  D.  (1992).  Information-based objective functions  for  active  data selec(cid:173)\\ntion,  Neural  Computation,  4,  590-604. \\nPaass,  G.,  and Kindermann, J. (1994).  Bayesian  Query Construction for  Neu(cid:173)\\nral  Network  Models.  In  G.  Tesauro  et  al.,  eds.,  Advances  in  Neural  Information \\nProcessing Systems  7,  MIT Press. \\nPlutowski, M.,  &  White,  H.  (1993).  Selecting concise  training sets from  clean \\ndata.  IEEE  Transactions  on  Neural  Networks,  4, 305-318. \\nSchaal,  S.  &  Atkeson,  C.  (1994).  Robot  Juggling:  An  Implementation  of \\nMemory-based Learning.  Control Systems 14, 57-71. \\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "authors_df = pd.read_csv('authors.csv')\n",
        "authors_df.to_sql('authors_raw', conn, if_exists = 'replace')\n",
        "display(authors_df)\n",
        "\n",
        "papers_df = pd.read_csv('papers.csv')\n",
        "papers_df.to_sql('papers_raw', conn, if_exists = 'replace')\n",
        "display(papers_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper_count= pd.read_sql_query(\"SELECT year, COUNT(year) as count FROM papers_raw GROUP BY year ORDER BY 1 asc\", conn)\n",
        "paper_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AWuKoZy3payC",
        "outputId": "e58ef8d6-31fa-4119-9a52-3ed2252abbeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year  count\n",
              "0   1987     90\n",
              "1   1988     94\n",
              "2   1989    101\n",
              "3   1990    143\n",
              "4   1991    144\n",
              "5   1992    127\n",
              "6   1993    158\n",
              "7   1994    140\n",
              "8   1995    152\n",
              "9   1996    152\n",
              "10  1997    150\n",
              "11  1998    151\n",
              "12  1999    150\n",
              "13  2000    152\n",
              "14  2001    197\n",
              "15  2002    207\n",
              "16  2003    198\n",
              "17  2004    207\n",
              "18  2005    207\n",
              "19  2006    204\n",
              "20  2007    217\n",
              "21  2008    250\n",
              "22  2009    262\n",
              "23  2010    292\n",
              "24  2011    306\n",
              "25  2012    370\n",
              "26  2013    360\n",
              "27  2014    411\n",
              "28  2015    403\n",
              "29  2016    569\n",
              "30  2017    679\n",
              "31  2018   1009\n",
              "32  2019   1428"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5b11ffe-28ae-4979-8121-7fc4b2f5b0d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1987</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1988</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1989</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1990</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1991</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1992</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1993</td>\n",
              "      <td>158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1995</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1996</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1997</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1998</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1999</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2000</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2001</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2002</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2003</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2004</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2005</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2006</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2007</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2008</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2009</td>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2010</td>\n",
              "      <td>292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2011</td>\n",
              "      <td>306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2012</td>\n",
              "      <td>370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2013</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2014</td>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2015</td>\n",
              "      <td>403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2016</td>\n",
              "      <td>569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2017</td>\n",
              "      <td>679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2018</td>\n",
              "      <td>1009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2019</td>\n",
              "      <td>1428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5b11ffe-28ae-4979-8121-7fc4b2f5b0d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5b11ffe-28ae-4979-8121-7fc4b2f5b0d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5b11ffe-28ae-4979-8121-7fc4b2f5b0d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e6be731-c826-4325-8be2-017338becd76\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e6be731-c826-4325-8be2-017338becd76')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e6be731-c826-4325-8be2-017338becd76 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a145c200-f027-4202-acfa-597644a9ab23\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('paper_count')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a145c200-f027-4202-acfa-597644a9ab23 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('paper_count');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "paper_count",
              "summary": "{\n  \"name\": \"paper_count\",\n  \"rows\": 33,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1987,\n        \"max\": 2019,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2018,\n          2002,\n          2013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 277,\n        \"min\": 90,\n        \"max\": 1428,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          150,\n          679,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(x = 'count', y = 'year', data = paper_count)\n",
        "plt.title('Number of papers per year')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "BJeKzPn1qbjR",
        "outputId": "66139593-877a-4dfd-ba9e-2caa44f57822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Number of papers per year')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "kXwDzBuTqwKn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
